<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/website-sg3390/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/website-sg3390/" rel="alternate" type="text/html" /><updated>2023-04-10T12:57:51-04:00</updated><id>http://localhost:4000/website-sg3390/feed.xml</id><title type="html">Serra’s Project Updates</title><subtitle>Weekly updates are below.</subtitle><author><name>Serra Goker</name></author><entry><title type="html">Update 6</title><link href="http://localhost:4000/website-sg3390/updates/update-6/" rel="alternate" type="text/html" title="Update 6" /><published>2023-04-10T00:00:00-04:00</published><updated>2023-04-10T00:00:00-04:00</updated><id>http://localhost:4000/website-sg3390/updates/update-6</id><content type="html" xml:base="http://localhost:4000/website-sg3390/updates/update-6/"><![CDATA[<p>This week I primarily worked on data analysis. To start the analysis I first concatenated all of my text data to a 
string array. Then utilizing the nltk library- which is a library commonly used for text processing- I tokenized my 
text. This was helpful because the data contained a lot of emojis and random characters. After that, I wanted to 
obtain the most frequent words that appear in my text so that I can assign sentiment values.</p>

<p>Unfortunately, I decided not to move forward with the pre-set Turkish sentiment analysis tools, because they haven’t 
yielded accurate representations of colloquial Turkish phrases. The project I am working on requires sentiment 
scores for colloquial phrases as it is sourced from the comments section of an e-commerce website.</p>

<p>After tokenizing the text and getting the single word frequencies, I decided that it would be a good approach to 
also look at longer expressions consisting of 2-3 words as well. Since many single word phrases don’t give out a 
clear sentiment. Hence, I obtained bigrams and trigrams again using the nltk library.</p>

<p>Here are the top 50 words that appear in my text corpus:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> # Unigram Frequencies
 [('çok', 130),
 ('.', 114),
 ('güzel', 93),
 ('geldi', 55),
 (',', 40),
 ('bir', 37),
 ('aldım', 36),
 ('Çok', 35),
 ('ve', 34),
 ('ederim', 32),
 ('ürün', 31),
 ('iyi', 28),
 ('gibi', 25),
 ('Ülker', 25),
 ('lezzetli', 21),
 ('teşekkür', 21),
 ('hediye', 20),
 ('kargo', 20),
 ('paket', 20),
 ('olarak', 19),
 ('teşekkürler', 19),
 ('için', 19),
 ('beğendim', 18),
 ('ama', 17),
 ('tarihi', 17),
 ('tavsiye', 16),
 ('harika', 16),
 ('daha', 16),
 ('tek', 15),
 ('tadı', 15),
 ('bu', 14),
 ('çikolata', 14),
 ('son', 14),
 ('uygun', 13),
 ('hızlı', 13),
 ('gayet', 13),
 ('kalitesi', 13),
 ('kullanma', 13),
 ('fiyat', 12),
 ('Ürün', 12),
 ('almıştım', 12),
 ('cok', 12),
 ('elime', 12),
 ('ulaştı', 12),
 ('güzeldi', 11),
 ('tam', 11),
 ('şekilde', 11),
 ('paketleme', 11),
 ('hepsi', 10),
 ('de', 10)]
</code></pre></div></div>

<p>Here are the bigram frequencies:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> [(('teşekkür', 'ederim'), 16), 
 (('tavsiye', 'ederim'), 15), 
 (('gibi', 'geldi'), 12), 
 (('kullanma', 'tarihi'), 10), 
 (('Ülker', 'kalitesi'), 10), 
 (('son', 'kullanma'), 9), 
 (('bir', 'şekilde'), 7), 
 (('elime', 'ulaştı'), 6), 
 (('hızlı', 'kargo'), 6), 
 (('memnun', 'kaldım'), 5), 
 (('tek', 'tek'), 5), 
 (('göründüğü', 'gibi'), 4), 
 (('Hızlı', 'kargo'), 4), 
 (('uygun', 'fiyata'), 4), 
 (('tarihi', 'yakın'), 4), 
 (('kahve', 'yanında'), 3),
 (('güvenilir', 'satıcı'), 3), 
 ((':', ')'), 3), 
 (('sağlam', 'paketlenmiş'), 3),
 (('mutlu', 'oldu'), 3), 
 (('istediğim', 'gibi'), 3), 
 (('biraz', 'daha'), 3), 
 (('daha', 'büyük'), 3), 
 (('Fiyatına', 'göre'), 2), 
 (('hesapliya', 'denk'), 2), 
 (('on', 'numara'), 2), 
 (('TL', 'ye'), 2), 
 (('good', 'good'), 2), 
 (('pul', 'şeklinde'), 2), 
 (('Daha', 'önce'), 2), 
 (('sipariş', 'vericem'), 2), 
 (('uzun', 'süre'), 2), 
 (('Ay', '2023'), 2), 
 (('memnun', 'kaldık'), 2), 
 (('!', '!'), 2),
 (('5', 'yıldız'), 2), 
 (('hepsi', 'birbirinden'), 2), 
 (('ürünlerin', 'hepsi'), 2), 
 (('tekrar', 'sipariş'), 2), 
 (('uyguna', 'geliyor'), 2), 
 (('tek', 'kelimeyle'), 2), 
 (('tarihine', 'de'), 2), 
 (('kelimeyle', 'harika'), 2), 
 (('Eylül', '2023'), 2), 
 (('Son', 'kullanma'), 2), 
 (('kalitesi', 'tartışılmaz'), 2), 
 (('Kardeşime', 'hediye'), 2), 
 (('Sevgilime', 'hediye'), 2), 
 (('arkadaşıma', 'hediye'), 2), 
 (('yakın', 'değil'), 2)]

</code></pre></div></div>

<p>And lastly the trigram frequencies:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> [(('son', 'kullanma', 'tarihi'), 7),
 (('göründüğü', 'gibi', 'geldi'), 4),
 (('olarak', 'aldım', 'çok'), 4),
 (('istediğim', 'gibi', 'geldi'), 3),
 (('de', 'çok', 'var'), 3),
 (('hediye', 'olarak', 'aldım'), 3),
 (('olarak', 'gönderdim', 'çok'), 3),
 (('bir', 'şekilde', 'geldi'), 3),
 (('aldım', 'çok', 'beğendi'), 3),
 (('tekrar', 'sipariş', 'vericem'), 2),
 (('denk', 'geldi', 'alinir'), 2),
 (('hesapliya', 'denk', 'geldi'), 2),
 (('Ay', '2023', 'olarak'), 2),
 (('biraz', 'daha', 'büyük'), 2),
 (('tek', 'kelimeyle', 'harika'), 2),
 (('çok', 'hesapliya', 'denk'), 2),
 (('Ülker', 'kalitesi', 'tartışılmaz'), 2),
 (('Kesinlikle', 'tavsiye', 'ederim'), 2),
 (('.', 'Ay', '2023'), 2),
 (('kullanma', 'tarihi', 'yakın'), 2),
 (('hepsi', 'birbirinden', 'güzel'), 2),
 (('iyi', 'İndirimden', 'aldım'), 2),
 (('kullanma', 'tarihi', 'de'), 2),
 (('hediye', 'olarak', 'gönderdim'), 2),
 (('tavsiye', 'ederim', 'Güzeldi'), 2),
 (('satıcıya', 'teşekkür', 'ederim'), 2),
 (('hediyesi', 'olarak', 'aldım'), 2),
 (('eksiksiz', 'bir', 'şekilde'), 2),
 (('ürün', 'göründüğü', 'gibi'), 2),
 (('teşekkür', 'ederim', 'ülker'), 2),
 (('sorunsuz', 'bir', 'şekilde'), 2),
 (('güzel', 'sağlam', 'paketlenmiş'), 2),
 (('gönderdim', 'çok', 'mutlu'), 2),
 (('tarihine', 'de', 'çok'), 2),
 (('fiyata', 'aldık', '.'), 2),
 (('.', 'Kesinlikle', 'tavsiye'), 2),
 (('çok', 'mutlu', 'oldu'), 2),
 (('ürünler', 'tam', 'geldi'), 2),
 (('çok', 'iyi', 'İndirimden'), 2),
 (('teşekkür', 'ederim', 'Ülker'), 2),
 (('teşekkür', 'ederim', 'Çok'), 2),
 (('geldi', 'tavsiye', 'ederim'), 2),
 (('elime', 'ulaştı', 'çok'), 2),
 (('ve', 'sağlam', 'geldi'), 2),
 (('tarihi', 'çok', 'yakın'), 2),
 (('geldi', 'teşekkür', 'ederim'), 2),
 (('iyi', 'bir', 'paket'), 2),
 (('guzel', 'çok', 'iyi'), 2),
 (('hızlı', 'kargo', 'güzel'), 2),
 (('.', 'Ülker', 'kalitesi'), 2)]
</code></pre></div></div>

<p>I will now go ahead and assign these positive or negative scores and compare how they vary by company.</p>]]></content><author><name>Serra Goker</name></author><category term="Updates" /><summary type="html"><![CDATA[This week I primarily worked on data analysis. To start the analysis I first concatenated all of my text data to a string array. Then utilizing the nltk library- which is a library commonly used for text processing- I tokenized my text. This was helpful because the data contained a lot of emojis and random characters. After that, I wanted to obtain the most frequent words that appear in my text so that I can assign sentiment values.]]></summary></entry><entry><title type="html">Update 5</title><link href="http://localhost:4000/website-sg3390/updates/update-5/" rel="alternate" type="text/html" title="Update 5" /><published>2023-04-03T00:00:00-04:00</published><updated>2023-04-03T00:00:00-04:00</updated><id>http://localhost:4000/website-sg3390/updates/update-5</id><content type="html" xml:base="http://localhost:4000/website-sg3390/updates/update-5/"><![CDATA[<h2 id="update-5-"><span style="color:Violet">Update 5 </span></h2>

<p>I found a sentiment analysis model utilized for <a href="https://github.com/serkanars/turkishsentimentanalysis">Turkish text</a>. Rather than using a pretrained model, I would have to 
train this model on my data and label certain expression as positive and negative. I am now going to go ahead and 
identify expressions that I think is important to consider for sentiment. To make this process easier I have 
produced a frequency diagram.</p>]]></content><author><name>Serra Goker</name></author><category term="Updates" /><summary type="html"><![CDATA[Update 5]]></summary></entry><entry><title type="html">Update 4</title><link href="http://localhost:4000/website-sg3390/updates/update-4/" rel="alternate" type="text/html" title="Update 4" /><published>2023-03-26T00:00:00-04:00</published><updated>2023-03-26T00:00:00-04:00</updated><id>http://localhost:4000/website-sg3390/updates/update-4</id><content type="html" xml:base="http://localhost:4000/website-sg3390/updates/update-4/"><![CDATA[<h2 id="the-api-works-"><span style="color:PaleVioletRed">The API Works! </span></h2>

<p>This week I managed to get my API to work and post the data I scraped. I am using the <a href="https://www.django-rest-framework.org/">Django Rest-Framework</a> to structure my API. Within the framework I created a table model to easily 
sort/modify the data I upload into the API. During the implementation stage, I got help from ChatGPT to structure my 
urls and views class. I also learned more about serialization. I created a serializers class that converts complex 
data types to Python objects which is then processed as json objects.</p>

<p>For this week, I aim to deploy my API on a server and have it global. I am looking into AWS and Microsoft Azure to 
see which one would be better in terms of the model I want to represent.</p>

<p>On the other hand, I am also researching what kind of analysis I want to conduct on my data. I have previously 
suggested that I can make a topic modeling, however thinking more about it I don’t think it will highlight the 
differences we want to see clearly. Instead of topic modeling, I could do a sentiment analysis/opinion mining. 
Opinion mining is very similar to sentiment analysis, however it is conducted on specific pre-identified feautures 
of the model.</p>

<p>The steps of applying opinion mining to the data would be:</p>
<ol>
  <li>Cleaning the data of stopwords, punctuation, converting to lower case, and tokenizing</li>
  <li>Extracting Features: this would have to be manually done by identifying key terms I would want to look at that 
are common in the data. I could do a frequency model for the most common words that appear in my data to render 
this process easier.</li>
  <li>Conducting sentiment analysis. One handicap with this part is that my data is in Turkish. I have found sentiment 
analysis models trained on Turkish corpus like <a href="https://textblob.readthedocs.io/en/dev/extensions.html#extensions">textblob-tr</a>. This library is not developed by text blob, so the 
accuracy is not guaranteed. SentiTurkNet is also another library that is developed off of Turkish corpus.</li>
  <li>Opinion aggregation: this step is basically combining the scores of each feature found in the previous step to 
gain a total score for the review.</li>
  <li>Visualization</li>
</ol>

<p>I am hoping to achieve the first two steps by next week!</p>]]></content><author><name>Serra Goker</name></author><category term="Updates" /><summary type="html"><![CDATA[The API Works!]]></summary></entry><entry><title type="html">Project Update Presentation</title><link href="http://localhost:4000/website-sg3390/presentation/midway-update/" rel="alternate" type="text/html" title="Project Update Presentation" /><published>2023-03-15T00:00:00-04:00</published><updated>2023-03-15T00:00:00-04:00</updated><id>http://localhost:4000/website-sg3390/presentation/midway-update</id><content type="html" xml:base="http://localhost:4000/website-sg3390/presentation/midway-update/"><![CDATA[<h4 id="this-is-a-presentation-of-everything-that-has-been-completed-in-this-project-so-far-"><span style="color:DarkMagenta">This is a presentation of everything that has been completed in this project so far. </span></h4>

<h2 id="what-is-the-project-"><span style="color:PaleVioletRed">What is the project? </span></h2>

<p>The goal of this project is to compare the reviews of three different products, produced from the same manufacturer 
and sold by different merchandisers. The manufacturer is Ulker (a leading food company in Turkey famous for its sweet
snacks). The products of Ulker can be found on the greatest e-commerce platform in Turkey: Trendyol. Similar to 
Amazon, you can get the same product from different sellers on Trendyol. We observed that the same product sold by 
different merchandisers have different concerns on the comments section. Therefore, we wanted to compare the comment 
section of three different products.</p>

<p>The products:</p>
<ol>
  <li><a href="https://www.trendyol.com/ulker/efsane-atistirmalik-paketi-p-32150980">Ulker Efsane Atistirmalik Paketi</a></li>
  <li><a href="https://www.trendyol.com/ulker/sutlu-pul-kuvertur-cikolata-eks-201-2-5-kg-p-41674124">Ulker Sutlu Pul Kuvertur Cikolata</a></li>
  <li><a href="https://www.trendyol.com/ulker/cikolata-all-star-paketi-p-37759574">Ulker Cikolata All-star Paketi</a></li>
</ol>

<h2 id="progress-of-the-project"><span style="color:PaleVioletRed">Progress of the Project</span></h2>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Identify the products to be used in analysis</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Implement a web scraper to obtain the comments from the website</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Clean and format the data, save and store in Excel files</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Implement a Django Rest Framework API and post the data</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Analyze the data</li>
</ul>

<ol>
  <li>Codes Implemented for Web Scraping:
    <ol>
      <li>Utilized Selenium and BeautifulSoup</li>
    </ol>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># open the browser 
</span>  <span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="p">.</span><span class="nc">Chrome</span><span class="p">(</span><span class="nc">ChromeDriverManager</span><span class="p">().</span><span class="nf">install</span><span class="p">())</span>
  <span class="n">browser</span><span class="p">.</span><span class="nf">maximize_window</span><span class="p">()</span>
  <span class="n">browser</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># load the page and manually sort comments, 
</span> <span class="c1"># then scroll down automatically
</span> <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
 <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">loop</span><span class="p">:</span>
     <span class="n">browser</span><span class="p">.</span><span class="nf">execute_script</span><span class="p">(</span><span class="s">"window.scrollBy(0, 700);"</span><span class="p">)</span>
     <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span>
     <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
     <span class="n">django_logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="s">' Loop number: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

 <span class="n">html</span> <span class="o">=</span> <span class="n">browser</span><span class="p">.</span><span class="n">page_source</span>
 <span class="n">soup</span> <span class="o">=</span> <span class="nc">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># Get the reviews 
</span> <span class="n">brand</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'seller-name-text'</span><span class="p">)</span>
 <span class="n">brand_score</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'sl-pn'</span><span class="p">)</span>

 <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span>

 <span class="n">browser</span><span class="p">.</span><span class="nf">execute_script</span><span class="p">(</span><span class="s">"window.scrollBy(0, 400);"</span><span class="p">)</span>
 <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
 <span class="n">competitors</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="nf">findAll</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'merchant-name-container'</span><span class="p">)</span>

 <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
 <span class="n">reviews</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'rnr-com-w'</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># store data in arrays 
</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">:</span>
     <span class="n">django_logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="s">' Review number: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
     <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
     <span class="n">review_div</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'rnr-com-tx'</span><span class="p">)</span>
     <span class="k">for</span> <span class="n">r_div</span> <span class="ow">in</span> <span class="n">review_div</span><span class="p">:</span>
         <span class="n">django_logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="s">' Review text: </span><span class="si">{</span><span class="n">r_div</span><span class="p">.</span><span class="n">text</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
         <span class="n">revs_arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">r_div</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>

     <span class="n">review_date</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'span'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'rnr-com-usr'</span><span class="p">)</span>
     <span class="k">for</span> <span class="n">r_date</span> <span class="ow">in</span> <span class="n">review_date</span><span class="p">:</span>
         <span class="n">date_review</span> <span class="o">=</span> <span class="n">r_date</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="s">'|'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
         <span class="n">django_logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="s">' Review text: </span><span class="si">{</span><span class="n">date_review</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
         <span class="n">dates_arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">convert</span><span class="p">(</span><span class="n">date_review</span><span class="p">))</span>

     <span class="n">review_shop</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'span'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'seller-name-info'</span><span class="p">)</span>
     <span class="k">for</span> <span class="n">r_shop</span> <span class="ow">in</span> <span class="n">review_shop</span><span class="p">:</span>
         <span class="n">django_logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="s">'store: </span><span class="si">{</span><span class="n">r_shop</span><span class="p">.</span><span class="n">text</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
         <span class="n">shops_arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">r_shop</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ol>

<p>Here is an example screenshot from the comments that were scraped:</p>

<p><img src="http://localhost:4000/website-sg3390/assets/images/ex_ss.jpg" alt="Unsplash image 9" /></p>

<p>Here is a screenshot showing how the data is stored in Excel Files:</p>

<p><img src="http://localhost:4000/website-sg3390/assets/images/excel_ss.png" alt="Unsplash image 0" /></p>

<h2 id="complications-and-problems-"><span style="color:PaleVioletRed">Complications and Problems: </span></h2>

<ol>
  <li>
    <p>Sorting the comments 
After automatically opening up the browser, we manually have to sort the comments from the drop-down menu. This is 
necessary to automate the process fully later on in the project.</p>
  </li>
  <li>
    <p>Obtaining the rating of the product in each review 
The html parsing of the stars are complicated to parse through. Here is a screenshot for how they are represented: 
<img src="http://localhost:4000/website-sg3390/assets/images/ss_html.png" alt="Unsplash image 1" />
Each star has an empty and full component, and they are present in both cases. I am now looking for a way to count 
the stars that are actually full.</p>
  </li>
</ol>

<h2 id="next-steps---"><span style="color:PaleVioletRed">Next Steps:   </span></h2>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Build an API to post the data tables
    <ul>
      <li>Any recommendations?</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Automate the process of scraping the data and posting to the API</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Analyze the differences of the data (waiting on further information from my supervisor)</li>
</ul>]]></content><author><name>Serra Goker</name></author><category term="Presentation" /><summary type="html"><![CDATA[This is a presentation of everything that has been completed in this project so far.]]></summary></entry><entry><title type="html">Update 3</title><link href="http://localhost:4000/website-sg3390/update-3/" rel="alternate" type="text/html" title="Update 3" /><published>2023-02-24T00:00:00-05:00</published><updated>2023-02-24T00:00:00-05:00</updated><id>http://localhost:4000/website-sg3390/update-3</id><content type="html" xml:base="http://localhost:4000/website-sg3390/update-3/"><![CDATA[<h2 id="update-week-4">Update Week 4</h2>

<h3 id="identifying-and-scraping-competitor-products">Identifying and scraping competitor products</h3>

<p>After meeting with my superviser, we have decided to add two other products from the same company to our analysis. 
These products are manufactured by Turkey’s third biggest food processing company <a href="https://www.statista.
com/statistics/937245/food-processing-companies-turkey/">Ulker</a>. However, the products manufactured by Ulker are sold by 
other food distributors- including local shops. So by obtaining data from two other products, we can see if there is 
a difference related to the manufacturer or the product.</p>]]></content><author><name>Serra Goker</name></author><summary type="html"><![CDATA[Update Week 4]]></summary></entry><entry><title type="html">Update 2</title><link href="http://localhost:4000/website-sg3390/update-2/" rel="alternate" type="text/html" title="Update 2" /><published>2023-02-20T00:00:00-05:00</published><updated>2023-02-20T00:00:00-05:00</updated><id>http://localhost:4000/website-sg3390/update-2</id><content type="html" xml:base="http://localhost:4000/website-sg3390/update-2/"><![CDATA[<h2 id="update-week-3">Update Week 3</h2>

<h3 id="formatting-the-data">Formatting the data</h3>

<p>Tools used for formatting the data:</p>
<ol>
  <li>pandas DataFrame</li>
</ol>

<p>To store the data in an efficient way and easily visualize it, I utilized the pandas package for python. However, 
before storing the data in a dataframe format, I had to convert the dates of the reviews from Turkish to English. 
Since there weren’t any libraries within python for this conversion, I came up with a hard coded converter that I am 
hoping to improve.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def conv_date(ad_date):
    new_date = ""
    if ad_date[1] == 'Ocak':
        new_date = "01/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Şubat':
        new_date = "02/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Mart':
        new_date = "03/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Nisan':
        new_date = "04/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Mayıs':
        new_date = "05/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Haziran':
        new_date = "06/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Temmuz':
        new_date = "07/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Ağustos':
        new_date = "08/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Eylül':
        new_date = "09/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Ekim':
        new_date = "10/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Kasım':
        new_date = "11/" + ad_date[0] + "/" + ad_date[2]
    elif ad_date[1] == 'Aralık':
        new_date = "12/" + ad_date[0] + "/" + ad_date[2]
    return new_date
</code></pre></div></div>

<p>After this conversion, I was able to store the data in the pandas dataframe. An advantage of the pandas package is 
its easy exportation to other file formats such as csv and excel. Since the reviews that I am storing are at most 
300 entries, it doesn’t require me to store it as a csv. Hence, I exported my data to Excel files for easy 
readability.</p>]]></content><author><name>Serra Goker</name></author><summary type="html"><![CDATA[Update Week 3]]></summary></entry><entry><title type="html">Update 1</title><link href="http://localhost:4000/website-sg3390/update-1/" rel="alternate" type="text/html" title="Update 1" /><published>2023-02-15T00:00:00-05:00</published><updated>2023-02-15T00:00:00-05:00</updated><id>http://localhost:4000/website-sg3390/update-1</id><content type="html" xml:base="http://localhost:4000/website-sg3390/update-1/"><![CDATA[<h2 id="update-week-2">Update Week 2</h2>

<h3 id="tools-to-be-used-for-the-project">Tools to be used for the project</h3>

<p>As mentioned in the proposal, this project will utilize web scraping tools to obtain data from websites. Web 
scraping refers to the automated process of extracting data from website using software tools. For the scope of this 
project I will utilize these tools:</p>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><a href="https://selenium-python.readthedocs.io/">Selenium</a></li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><a href="https://pypi.org/project/beautifulsoup4/#:~:text=Beautiful%20Soup%20is%20a%20library,
and%20modifying%20the%20parse%20tree.">beautifulsoup4</a></li>
</ul>

<p>As the webpage that I am scraping has a dynamic comments section, the ChromeDriver package from Selenium opens up a 
chrome browser run by the script. This script scrolls down to the comments section of the product. With the sleep 
functionality of chromedriver, the browser freezes for 3 seconds before proceeding to scraping the comments. During 
these three seconds, I click the sort comments by date dropdown to ease the process of refining the latest comments. 
This is currently a loophole I am intending to fix, so that the scraping can be fully automated.</p>

<p>After sorting the comments, utilizing beautifulsoup4, I parsed the date, the text of the comment, and the seller 
name. Another challenge that arose during this process was parsing the score of the review. The score of the review 
is represented in the html as star icons filled in. I will be working furter on this challenge to come up with a way 
to parse the scores as well.</p>

<h4 id="to-do-for-next-time">To-do for next time:</h4>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />automate date sorting</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />parse review scores</li>
</ul>]]></content><author><name>Serra Goker</name></author><summary type="html"><![CDATA[Update Week 2]]></summary></entry><entry><title type="html">Project Proposal</title><link href="http://localhost:4000/website-sg3390/proposal/proposal/" rel="alternate" type="text/html" title="Project Proposal" /><published>2023-02-12T00:00:00-05:00</published><updated>2023-02-12T00:00:00-05:00</updated><id>http://localhost:4000/website-sg3390/proposal/proposal</id><content type="html" xml:base="http://localhost:4000/website-sg3390/proposal/proposal/"><![CDATA[<h2 id="project-proposal">Project Proposal</h2>

<p>This project will focus on building a tool that compares the performance of different e-commerce websites. More than ever, people have
been shopping online to get whatever they need delivered to their doorstep without stepping out of their apartments. As shopping online
became the habit for many people, more e-commerce businesses were created to supply for the high demand. The same product can be bought 
from Amazon as well as eBay or Walmart. In that case, which seller should the user prefer? Is there a way to identify the advantages or 
disadvantages of getting the same product from different sellers?</p>

<p>In an effort to answer these questions, this project will develop a system that compares the performance of the same product across 
different e-commerce sellers. By identifying the differences across platforms, this algorithm will recommend buyers the best platform
to obtain their product from. Furthermore, it will point out the lacking parts of the seller and will propose the areas where they need
to improve their service.</p>

<p>To quantify the analysis, the project will utilize a webscraping tool to obtain the comments under a certain product from the website.
After getting the initial data, a topic modeling algorithm (LDA/TF-IDF) will be used to extract specific concerns from the text data. 
These concerns could be related to packaging, delivery time, customer care, etc.</p>

<p>The last step for this project is going to be building website that showcases the differences between companies on interactive 
visuals that will best represent the analysis.</p>

<p>Previously, I have developed programs that utilized webscraping in static website. The challenge of this project will be to build 
one for a dynamic website.</p>]]></content><author><name>Serra Goker</name></author><category term="Proposal" /><summary type="html"><![CDATA[Project Proposal]]></summary></entry></feed>